{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using HTTP\n",
    "using Dates\n",
    "using CSV\n",
    "using DataFrames\n",
    "using Geodesy\n",
    "using JSON\n",
    "using DataStructures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"../cities_csv/world_cities_data.csv\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = \"https://api.darksky.net/forecast\"\n",
    "earthquakes_csv = \"../earthquakes_csv/1999_2017_earthquakes_magnitude_7-9.csv\" #magnitude 7-9\n",
    "cities_csv = \"../cities_csv/world_cities_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "read_apikey (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function read_apikey(apikey_file)\n",
    "    key = open(apikey_file) do file\n",
    "          readlines(file)\n",
    "        end \n",
    "    return String(key[1])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done reading apikey!\n"
     ]
    }
   ],
   "source": [
    "apikey = read_apikey(\"darksky_api.txt\")\n",
    "println(\"Done reading apikey!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>Column1</th><th>datetime</th><th>latitude</th><th>longitude</th><th>depth</th><th>magnitude</th></tr><tr><th></th><th>Int64</th><th>String</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>263 rows × 6 columns</p><tr><th>1</th><td>96</td><td>2000-01-08T16:47:20.580Z</td><td>-16.925</td><td>-174.248</td><td>183.4</td><td>7.2</td></tr><tr><th>2</th><td>571</td><td>2000-02-25T01:43:58.640Z</td><td>-19.528</td><td>173.818</td><td>33.0</td><td>7.1</td></tr><tr><th>3</th><td>891</td><td>2000-03-28T11:00:22.510Z</td><td>22.338</td><td>143.73</td><td>126.5</td><td>7.6</td></tr><tr><th>4</th><td>1149</td><td>2000-04-23T09:27:23.320Z</td><td>-28.307</td><td>-62.99</td><td>608.5</td><td>7.0</td></tr><tr><th>5</th><td>1297</td><td>2000-05-04T04:21:16.210Z</td><td>-1.105</td><td>123.573</td><td>26.0</td><td>7.6</td></tr><tr><th>6</th><td>1420</td><td>2000-05-12T18:43:18.120Z</td><td>-23.548</td><td>-66.452</td><td>225.0</td><td>7.2</td></tr><tr><th>7</th><td>1674</td><td>2000-06-04T16:28:26.170Z</td><td>-4.721</td><td>102.087</td><td>33.0</td><td>7.9</td></tr><tr><th>8</th><td>1997</td><td>2000-06-18T14:44:13.310Z</td><td>-13.802</td><td>97.453</td><td>10.0</td><td>7.9</td></tr><tr><th>9</th><td>2869</td><td>2000-08-06T07:27:12.900Z</td><td>28.856</td><td>139.556</td><td>394.8</td><td>7.4</td></tr><tr><th>10</th><td>3602</td><td>2000-10-04T16:58:44.310Z</td><td>-15.421</td><td>166.91</td><td>23.0</td><td>7.0</td></tr><tr><th>11</th><td>3885</td><td>2000-10-29T08:37:08.770Z</td><td>-4.766</td><td>153.945</td><td>50.0</td><td>7.0</td></tr><tr><th>12</th><td>4100</td><td>2000-11-16T04:54:56.740Z</td><td>-3.98</td><td>152.169</td><td>33.0</td><td>8.0</td></tr><tr><th>13</th><td>4128</td><td>2000-11-16T07:42:16.930Z</td><td>-5.233</td><td>153.102</td><td>30.0</td><td>7.8</td></tr><tr><th>14</th><td>4275</td><td>2000-11-17T21:01:56.490Z</td><td>-5.496</td><td>151.781</td><td>33.0</td><td>7.8</td></tr><tr><th>15</th><td>4694</td><td>2000-12-06T17:11:06.400Z</td><td>39.566</td><td>54.799</td><td>30.0</td><td>7.0</td></tr><tr><th>16</th><td>5025</td><td>2001-01-01T06:57:04.170Z</td><td>6.898</td><td>126.579</td><td>33.0</td><td>7.5</td></tr><tr><th>17</th><td>5135</td><td>2001-01-09T16:49:28.000Z</td><td>-14.928</td><td>167.17</td><td>103.0</td><td>7.1</td></tr><tr><th>18</th><td>5148</td><td>2001-01-10T16:02:44.230Z</td><td>57.078</td><td>-153.211</td><td>33.0</td><td>7.0</td></tr><tr><th>19</th><td>5176</td><td>2001-01-13T17:33:32.380Z</td><td>13.049</td><td>-88.66</td><td>60.0</td><td>7.7</td></tr><tr><th>20</th><td>5333</td><td>2001-01-26T03:16:40.500Z</td><td>23.419</td><td>70.232</td><td>16.0</td><td>7.7</td></tr><tr><th>21</th><td>5557</td><td>2001-02-13T19:28:30.260Z</td><td>-4.68</td><td>102.562</td><td>36.0</td><td>7.4</td></tr><tr><th>22</th><td>5702</td><td>2001-02-24T07:23:48.730Z</td><td>1.271</td><td>126.249</td><td>35.0</td><td>7.1</td></tr><tr><th>23</th><td>6863</td><td>2001-06-03T02:41:57.160Z</td><td>-29.666</td><td>-178.633</td><td>178.1</td><td>7.2</td></tr><tr><th>24</th><td>7116</td><td>2001-06-23T20:33:14.130Z</td><td>-16.265</td><td>-73.641</td><td>33.0</td><td>8.4</td></tr><tr><th>25</th><td>7439</td><td>2001-07-07T09:38:43.520Z</td><td>-17.543</td><td>-72.077</td><td>33.0</td><td>7.6</td></tr><tr><th>26</th><td>7979</td><td>2001-08-21T06:52:06.250Z</td><td>-36.813</td><td>-179.575</td><td>33.0</td><td>7.1</td></tr><tr><th>27</th><td>8703</td><td>2001-10-12T15:02:16.840Z</td><td>12.686</td><td>144.98</td><td>37.0</td><td>7.0</td></tr><tr><th>28</th><td>8777</td><td>2001-10-19T03:28:44.460Z</td><td>-4.102</td><td>123.907</td><td>33.0</td><td>7.5</td></tr><tr><th>29</th><td>8944</td><td>2001-10-31T09:10:20.000Z</td><td>-5.912</td><td>150.196</td><td>33.0</td><td>7.0</td></tr><tr><th>30</th><td>9122</td><td>2001-11-14T09:26:10.010Z</td><td>35.946</td><td>90.541</td><td>10.0</td><td>7.8</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& Column1 & datetime & latitude & longitude & depth & magnitude\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & String & Float64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 96 & 2000-01-08T16:47:20.580Z & -16.925 & -174.248 & 183.4 & 7.2 \\\\\n",
       "\t2 & 571 & 2000-02-25T01:43:58.640Z & -19.528 & 173.818 & 33.0 & 7.1 \\\\\n",
       "\t3 & 891 & 2000-03-28T11:00:22.510Z & 22.338 & 143.73 & 126.5 & 7.6 \\\\\n",
       "\t4 & 1149 & 2000-04-23T09:27:23.320Z & -28.307 & -62.99 & 608.5 & 7.0 \\\\\n",
       "\t5 & 1297 & 2000-05-04T04:21:16.210Z & -1.105 & 123.573 & 26.0 & 7.6 \\\\\n",
       "\t6 & 1420 & 2000-05-12T18:43:18.120Z & -23.548 & -66.452 & 225.0 & 7.2 \\\\\n",
       "\t7 & 1674 & 2000-06-04T16:28:26.170Z & -4.721 & 102.087 & 33.0 & 7.9 \\\\\n",
       "\t8 & 1997 & 2000-06-18T14:44:13.310Z & -13.802 & 97.453 & 10.0 & 7.9 \\\\\n",
       "\t9 & 2869 & 2000-08-06T07:27:12.900Z & 28.856 & 139.556 & 394.8 & 7.4 \\\\\n",
       "\t10 & 3602 & 2000-10-04T16:58:44.310Z & -15.421 & 166.91 & 23.0 & 7.0 \\\\\n",
       "\t11 & 3885 & 2000-10-29T08:37:08.770Z & -4.766 & 153.945 & 50.0 & 7.0 \\\\\n",
       "\t12 & 4100 & 2000-11-16T04:54:56.740Z & -3.98 & 152.169 & 33.0 & 8.0 \\\\\n",
       "\t13 & 4128 & 2000-11-16T07:42:16.930Z & -5.233 & 153.102 & 30.0 & 7.8 \\\\\n",
       "\t14 & 4275 & 2000-11-17T21:01:56.490Z & -5.496 & 151.781 & 33.0 & 7.8 \\\\\n",
       "\t15 & 4694 & 2000-12-06T17:11:06.400Z & 39.566 & 54.799 & 30.0 & 7.0 \\\\\n",
       "\t16 & 5025 & 2001-01-01T06:57:04.170Z & 6.898 & 126.579 & 33.0 & 7.5 \\\\\n",
       "\t17 & 5135 & 2001-01-09T16:49:28.000Z & -14.928 & 167.17 & 103.0 & 7.1 \\\\\n",
       "\t18 & 5148 & 2001-01-10T16:02:44.230Z & 57.078 & -153.211 & 33.0 & 7.0 \\\\\n",
       "\t19 & 5176 & 2001-01-13T17:33:32.380Z & 13.049 & -88.66 & 60.0 & 7.7 \\\\\n",
       "\t20 & 5333 & 2001-01-26T03:16:40.500Z & 23.419 & 70.232 & 16.0 & 7.7 \\\\\n",
       "\t21 & 5557 & 2001-02-13T19:28:30.260Z & -4.68 & 102.562 & 36.0 & 7.4 \\\\\n",
       "\t22 & 5702 & 2001-02-24T07:23:48.730Z & 1.271 & 126.249 & 35.0 & 7.1 \\\\\n",
       "\t23 & 6863 & 2001-06-03T02:41:57.160Z & -29.666 & -178.633 & 178.1 & 7.2 \\\\\n",
       "\t24 & 7116 & 2001-06-23T20:33:14.130Z & -16.265 & -73.641 & 33.0 & 8.4 \\\\\n",
       "\t25 & 7439 & 2001-07-07T09:38:43.520Z & -17.543 & -72.077 & 33.0 & 7.6 \\\\\n",
       "\t26 & 7979 & 2001-08-21T06:52:06.250Z & -36.813 & -179.575 & 33.0 & 7.1 \\\\\n",
       "\t27 & 8703 & 2001-10-12T15:02:16.840Z & 12.686 & 144.98 & 37.0 & 7.0 \\\\\n",
       "\t28 & 8777 & 2001-10-19T03:28:44.460Z & -4.102 & 123.907 & 33.0 & 7.5 \\\\\n",
       "\t29 & 8944 & 2001-10-31T09:10:20.000Z & -5.912 & 150.196 & 33.0 & 7.0 \\\\\n",
       "\t30 & 9122 & 2001-11-14T09:26:10.010Z & 35.946 & 90.541 & 10.0 & 7.8 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "263×6 DataFrame. Omitted printing of 1 columns\n",
       "│ Row │ Column1 │ datetime                 │ latitude │ longitude │ depth   │\n",
       "│     │ \u001b[90mInt64\u001b[39m   │ \u001b[90mString\u001b[39m                   │ \u001b[90mFloat64\u001b[39m  │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m │\n",
       "├─────┼─────────┼──────────────────────────┼──────────┼───────────┼─────────┤\n",
       "│ 1   │ 96      │ 2000-01-08T16:47:20.580Z │ -16.925  │ -174.248  │ 183.4   │\n",
       "│ 2   │ 571     │ 2000-02-25T01:43:58.640Z │ -19.528  │ 173.818   │ 33.0    │\n",
       "│ 3   │ 891     │ 2000-03-28T11:00:22.510Z │ 22.338   │ 143.73    │ 126.5   │\n",
       "│ 4   │ 1149    │ 2000-04-23T09:27:23.320Z │ -28.307  │ -62.99    │ 608.5   │\n",
       "│ 5   │ 1297    │ 2000-05-04T04:21:16.210Z │ -1.105   │ 123.573   │ 26.0    │\n",
       "│ 6   │ 1420    │ 2000-05-12T18:43:18.120Z │ -23.548  │ -66.452   │ 225.0   │\n",
       "│ 7   │ 1674    │ 2000-06-04T16:28:26.170Z │ -4.721   │ 102.087   │ 33.0    │\n",
       "│ 8   │ 1997    │ 2000-06-18T14:44:13.310Z │ -13.802  │ 97.453    │ 10.0    │\n",
       "│ 9   │ 2869    │ 2000-08-06T07:27:12.900Z │ 28.856   │ 139.556   │ 394.8   │\n",
       "│ 10  │ 3602    │ 2000-10-04T16:58:44.310Z │ -15.421  │ 166.91    │ 23.0    │\n",
       "⋮\n",
       "│ 253 │ 107307  │ 2016-11-13T11:02:56.340Z │ -42.7373 │ 173.054   │ 15.11   │\n",
       "│ 254 │ 107978  │ 2016-12-08T17:38:46.280Z │ -10.6812 │ 161.327   │ 40.0    │\n",
       "│ 255 │ 108286  │ 2016-12-17T10:51:10.500Z │ -4.5049  │ 153.522   │ 94.54   │\n",
       "│ 256 │ 108601  │ 2016-12-25T14:22:27.010Z │ -43.4064 │ -73.9413  │ 38.0    │\n",
       "│ 257 │ 108927  │ 2017-01-10T06:13:48.140Z │ 4.4782   │ 122.617   │ 627.17  │\n",
       "│ 258 │ 109134  │ 2017-01-22T04:30:22.960Z │ -6.2464  │ 155.172   │ 135.0   │\n",
       "│ 259 │ 111975  │ 2017-07-17T23:34:13.740Z │ 54.4434  │ 168.857   │ 10.0    │\n",
       "│ 260 │ 112791  │ 2017-09-08T04:49:19.180Z │ 15.0222  │ -93.8993  │ 47.39   │\n",
       "│ 261 │ 113078  │ 2017-09-19T18:14:38.090Z │ 18.5499  │ -98.4887  │ 48.0    │\n",
       "│ 262 │ 114101  │ 2017-11-12T18:18:17.180Z │ 34.9109  │ 45.9592   │ 19.0    │\n",
       "│ 263 │ 114340  │ 2017-11-19T22:43:29.250Z │ -21.3246 │ 168.672   │ 10.0    │"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earthquakes_df = DataFrame(CSV.File(earthquakes_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unix_time (generic function with 1 method)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function unix_time(earthquake_time)\n",
    "    \n",
    "    if last(earthquake_time) == \"Z\"\n",
    "        eq_time = strip(earthquake_time, last(earthquake_time))\n",
    "    else\n",
    "        eq_time = earthquake_time\n",
    "    end\n",
    "    \n",
    "    return round(Int, Dates.datetime2unix(DateTime(eq_time)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "darksky_api_call (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function darksky_api_call(url)\n",
    "    try\n",
    "        response = HTTP.get(url)\n",
    "        return String(response.body)\n",
    "        catch e\n",
    "        return \"Error occured: $e\"\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cities_data (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function cities_data()\n",
    "     return DataFrame(CSV.File(cities_csv))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "forecast_weather (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function forecast_weather(latitude, longitude)\n",
    "    forecast_url = base_url * \"/\" * apikey * \"/\" * string(latitude) * \",\" * string(longitude)\n",
    "    return darksky_api_call(forecast_url)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_historical_weather (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_historical_weather(latitude, longitude, earthquake_datetime)\n",
    "    if typeof(earthquake_datetime) != Int64 \n",
    "        unix_timestamp = unix_time(earthquake_datetime)\n",
    "    else\n",
    "        unix_timestamp = earthquake_datetime\n",
    "    end\n",
    "    \n",
    "    historical_temperature_url = base_url * \"/\" * apikey * \"/\" * string(latitude) * \",\" * string(longitude) * \",\" * string(unix_timestamp)\n",
    "    return darksky_api_call(historical_temperature_url)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "find_nearest_city (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will return the nearest city lat, lon and the distance in kilometers\n",
    "function find_nearest_city(lat, lon)\n",
    "    distancearray = []\n",
    "    cities_df = cities_data() # This will receive a table, with the city data\n",
    "    \n",
    "    for i in eachrow(cities_df)\n",
    "       city_coords = LLA(i[\"latitude\"],i[\"longitude\"])\n",
    "       point = LLA(lat, lon)\n",
    "       push!(distancearray, distance(city_coords, point)/1000)\n",
    "    end\n",
    "    \n",
    "    distance_kms, index = findmin(distancearray)\n",
    "    #nearest_city_lat, nearest_city_lon = cities_df[index, 3:4] # this returns a dataframe row, keeping this line to remember two ways to accomplish this\n",
    "    nearest_city_lat, nearest_city_lon = cities_df[index, [\"latitude\", \"longitude\"]] # this returns a dataframe row\n",
    "    return nearest_city_lat, nearest_city_lon, round(distance_kms, digits=0)\n",
    "        \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_earthquakes_nearest_cities_df (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the closest city to the earthquake\n",
    "function create_earthquakes_nearest_cities_df()\n",
    "   # eq_cities = DataFrame(nearest_city_latitude = Float64[], nearest_city_longitude = Float64[], nearest_city_distance = Float64[])\n",
    "    \n",
    "    eq_cities_df = DataFrame(earthquake_time = String[],\n",
    "                            earthquake_latitude = Float64[],\n",
    "                            earthquake_longitude = Float64[],\n",
    "                            earthquake_depth = Float64[],\n",
    "                            earthquake_magnitude = Float64[],\n",
    "                            nearest_city_latitude = Float64[],\n",
    "                            nearest_city_longitude = Float64[],\n",
    "                            nearest_city_distance = Float64[])\n",
    "    \n",
    "    for earthquake in eachrow(earthquakes_df)\n",
    "        city_latitude, city_longitude, city_distance_kilometers = find_nearest_city(earthquake[\"latitude\"], earthquake[\"longitude\"])\n",
    "        push!(eq_cities_df, (earthquake_time = earthquake[\"datetime\"],\n",
    "                            earthquake_latitude = earthquake[\"latitude\"],\n",
    "                            earthquake_longitude = earthquake[\"longitude\"],\n",
    "                            earthquake_depth = earthquake[\"depth\"],\n",
    "                            earthquake_magnitude = earthquake[\"magnitude\"],\n",
    "                            nearest_city_latitude = city_latitude,\n",
    "                            nearest_city_longitude = city_longitude,\n",
    "                            nearest_city_distance = city_distance_kilometers))\n",
    "    end\n",
    "    return eq_cities_df\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keeping the \"yes\" data should be the only option,  I chose to all keep the \"no\" in case I find an alternate weather datasource.\n",
    "If I want the data for which the historical data is available, then I will just filter the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_earthquakes_cities_historical_weather_df (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will have to be merged with the eq79 data since the nearest_city is the best chance at historical weather data to be available\n",
    "function create_earthquakes_cities_historical_weather_df()\n",
    "    \n",
    "    nearestcity_df = create_earthquakes_nearest_cities_df()\n",
    "    \n",
    "    weather = []\n",
    "    for city in eachrow(nearestcity_df)\n",
    "        apicall_response = get_historical_weather(city[\"nearest_city_latitude\"],city[\"nearest_city_longitude\"],city[\"earthquake_time\"])\n",
    "        h = JSON.parse(apicall_response)\n",
    "        \n",
    "        if haskey(h[\"currently\"], \"apparentTemperature\")\n",
    "            push!(weather, \"yes\")\n",
    "        else\n",
    "            push!(weather, \"no\")\n",
    "        end\n",
    "    end\n",
    "    insertcols!(nearestcity_df, :historical_temp_available => weather)\n",
    "    return nearestcity_df # return table with weather availability\n",
    "        \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>earthquake_time</th><th>earthquake_latitude</th><th>earthquake_longitude</th><th>earthquake_depth</th></tr><tr><th></th><th>String</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>263 rows × 9 columns (omitted printing of 5 columns)</p><tr><th>1</th><td>2000-01-08T16:47:20.580Z</td><td>-16.925</td><td>-174.248</td><td>183.4</td></tr><tr><th>2</th><td>2000-02-25T01:43:58.640Z</td><td>-19.528</td><td>173.818</td><td>33.0</td></tr><tr><th>3</th><td>2000-03-28T11:00:22.510Z</td><td>22.338</td><td>143.73</td><td>126.5</td></tr><tr><th>4</th><td>2000-04-23T09:27:23.320Z</td><td>-28.307</td><td>-62.99</td><td>608.5</td></tr><tr><th>5</th><td>2000-05-04T04:21:16.210Z</td><td>-1.105</td><td>123.573</td><td>26.0</td></tr><tr><th>6</th><td>2000-05-12T18:43:18.120Z</td><td>-23.548</td><td>-66.452</td><td>225.0</td></tr><tr><th>7</th><td>2000-06-04T16:28:26.170Z</td><td>-4.721</td><td>102.087</td><td>33.0</td></tr><tr><th>8</th><td>2000-06-18T14:44:13.310Z</td><td>-13.802</td><td>97.453</td><td>10.0</td></tr><tr><th>9</th><td>2000-08-06T07:27:12.900Z</td><td>28.856</td><td>139.556</td><td>394.8</td></tr><tr><th>10</th><td>2000-10-04T16:58:44.310Z</td><td>-15.421</td><td>166.91</td><td>23.0</td></tr><tr><th>11</th><td>2000-10-29T08:37:08.770Z</td><td>-4.766</td><td>153.945</td><td>50.0</td></tr><tr><th>12</th><td>2000-11-16T04:54:56.740Z</td><td>-3.98</td><td>152.169</td><td>33.0</td></tr><tr><th>13</th><td>2000-11-16T07:42:16.930Z</td><td>-5.233</td><td>153.102</td><td>30.0</td></tr><tr><th>14</th><td>2000-11-17T21:01:56.490Z</td><td>-5.496</td><td>151.781</td><td>33.0</td></tr><tr><th>15</th><td>2000-12-06T17:11:06.400Z</td><td>39.566</td><td>54.799</td><td>30.0</td></tr><tr><th>16</th><td>2001-01-01T06:57:04.170Z</td><td>6.898</td><td>126.579</td><td>33.0</td></tr><tr><th>17</th><td>2001-01-09T16:49:28.000Z</td><td>-14.928</td><td>167.17</td><td>103.0</td></tr><tr><th>18</th><td>2001-01-10T16:02:44.230Z</td><td>57.078</td><td>-153.211</td><td>33.0</td></tr><tr><th>19</th><td>2001-01-13T17:33:32.380Z</td><td>13.049</td><td>-88.66</td><td>60.0</td></tr><tr><th>20</th><td>2001-01-26T03:16:40.500Z</td><td>23.419</td><td>70.232</td><td>16.0</td></tr><tr><th>21</th><td>2001-02-13T19:28:30.260Z</td><td>-4.68</td><td>102.562</td><td>36.0</td></tr><tr><th>22</th><td>2001-02-24T07:23:48.730Z</td><td>1.271</td><td>126.249</td><td>35.0</td></tr><tr><th>23</th><td>2001-06-03T02:41:57.160Z</td><td>-29.666</td><td>-178.633</td><td>178.1</td></tr><tr><th>24</th><td>2001-06-23T20:33:14.130Z</td><td>-16.265</td><td>-73.641</td><td>33.0</td></tr><tr><th>25</th><td>2001-07-07T09:38:43.520Z</td><td>-17.543</td><td>-72.077</td><td>33.0</td></tr><tr><th>26</th><td>2001-08-21T06:52:06.250Z</td><td>-36.813</td><td>-179.575</td><td>33.0</td></tr><tr><th>27</th><td>2001-10-12T15:02:16.840Z</td><td>12.686</td><td>144.98</td><td>37.0</td></tr><tr><th>28</th><td>2001-10-19T03:28:44.460Z</td><td>-4.102</td><td>123.907</td><td>33.0</td></tr><tr><th>29</th><td>2001-10-31T09:10:20.000Z</td><td>-5.912</td><td>150.196</td><td>33.0</td></tr><tr><th>30</th><td>2001-11-14T09:26:10.010Z</td><td>35.946</td><td>90.541</td><td>10.0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccc}\n",
       "\t& earthquake\\_time & earthquake\\_latitude & earthquake\\_longitude & earthquake\\_depth & \\\\\n",
       "\t\\hline\n",
       "\t& String & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 2000-01-08T16:47:20.580Z & -16.925 & -174.248 & 183.4 & $\\dots$ \\\\\n",
       "\t2 & 2000-02-25T01:43:58.640Z & -19.528 & 173.818 & 33.0 & $\\dots$ \\\\\n",
       "\t3 & 2000-03-28T11:00:22.510Z & 22.338 & 143.73 & 126.5 & $\\dots$ \\\\\n",
       "\t4 & 2000-04-23T09:27:23.320Z & -28.307 & -62.99 & 608.5 & $\\dots$ \\\\\n",
       "\t5 & 2000-05-04T04:21:16.210Z & -1.105 & 123.573 & 26.0 & $\\dots$ \\\\\n",
       "\t6 & 2000-05-12T18:43:18.120Z & -23.548 & -66.452 & 225.0 & $\\dots$ \\\\\n",
       "\t7 & 2000-06-04T16:28:26.170Z & -4.721 & 102.087 & 33.0 & $\\dots$ \\\\\n",
       "\t8 & 2000-06-18T14:44:13.310Z & -13.802 & 97.453 & 10.0 & $\\dots$ \\\\\n",
       "\t9 & 2000-08-06T07:27:12.900Z & 28.856 & 139.556 & 394.8 & $\\dots$ \\\\\n",
       "\t10 & 2000-10-04T16:58:44.310Z & -15.421 & 166.91 & 23.0 & $\\dots$ \\\\\n",
       "\t11 & 2000-10-29T08:37:08.770Z & -4.766 & 153.945 & 50.0 & $\\dots$ \\\\\n",
       "\t12 & 2000-11-16T04:54:56.740Z & -3.98 & 152.169 & 33.0 & $\\dots$ \\\\\n",
       "\t13 & 2000-11-16T07:42:16.930Z & -5.233 & 153.102 & 30.0 & $\\dots$ \\\\\n",
       "\t14 & 2000-11-17T21:01:56.490Z & -5.496 & 151.781 & 33.0 & $\\dots$ \\\\\n",
       "\t15 & 2000-12-06T17:11:06.400Z & 39.566 & 54.799 & 30.0 & $\\dots$ \\\\\n",
       "\t16 & 2001-01-01T06:57:04.170Z & 6.898 & 126.579 & 33.0 & $\\dots$ \\\\\n",
       "\t17 & 2001-01-09T16:49:28.000Z & -14.928 & 167.17 & 103.0 & $\\dots$ \\\\\n",
       "\t18 & 2001-01-10T16:02:44.230Z & 57.078 & -153.211 & 33.0 & $\\dots$ \\\\\n",
       "\t19 & 2001-01-13T17:33:32.380Z & 13.049 & -88.66 & 60.0 & $\\dots$ \\\\\n",
       "\t20 & 2001-01-26T03:16:40.500Z & 23.419 & 70.232 & 16.0 & $\\dots$ \\\\\n",
       "\t21 & 2001-02-13T19:28:30.260Z & -4.68 & 102.562 & 36.0 & $\\dots$ \\\\\n",
       "\t22 & 2001-02-24T07:23:48.730Z & 1.271 & 126.249 & 35.0 & $\\dots$ \\\\\n",
       "\t23 & 2001-06-03T02:41:57.160Z & -29.666 & -178.633 & 178.1 & $\\dots$ \\\\\n",
       "\t24 & 2001-06-23T20:33:14.130Z & -16.265 & -73.641 & 33.0 & $\\dots$ \\\\\n",
       "\t25 & 2001-07-07T09:38:43.520Z & -17.543 & -72.077 & 33.0 & $\\dots$ \\\\\n",
       "\t26 & 2001-08-21T06:52:06.250Z & -36.813 & -179.575 & 33.0 & $\\dots$ \\\\\n",
       "\t27 & 2001-10-12T15:02:16.840Z & 12.686 & 144.98 & 37.0 & $\\dots$ \\\\\n",
       "\t28 & 2001-10-19T03:28:44.460Z & -4.102 & 123.907 & 33.0 & $\\dots$ \\\\\n",
       "\t29 & 2001-10-31T09:10:20.000Z & -5.912 & 150.196 & 33.0 & $\\dots$ \\\\\n",
       "\t30 & 2001-11-14T09:26:10.010Z & 35.946 & 90.541 & 10.0 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "263×9 DataFrame. Omitted printing of 6 columns\n",
       "│ Row │ earthquake_time          │ earthquake_latitude │ earthquake_longitude │\n",
       "│     │ \u001b[90mString\u001b[39m                   │ \u001b[90mFloat64\u001b[39m             │ \u001b[90mFloat64\u001b[39m              │\n",
       "├─────┼──────────────────────────┼─────────────────────┼──────────────────────┤\n",
       "│ 1   │ 2000-01-08T16:47:20.580Z │ -16.925             │ -174.248             │\n",
       "│ 2   │ 2000-02-25T01:43:58.640Z │ -19.528             │ 173.818              │\n",
       "│ 3   │ 2000-03-28T11:00:22.510Z │ 22.338              │ 143.73               │\n",
       "│ 4   │ 2000-04-23T09:27:23.320Z │ -28.307             │ -62.99               │\n",
       "│ 5   │ 2000-05-04T04:21:16.210Z │ -1.105              │ 123.573              │\n",
       "│ 6   │ 2000-05-12T18:43:18.120Z │ -23.548             │ -66.452              │\n",
       "│ 7   │ 2000-06-04T16:28:26.170Z │ -4.721              │ 102.087              │\n",
       "│ 8   │ 2000-06-18T14:44:13.310Z │ -13.802             │ 97.453               │\n",
       "│ 9   │ 2000-08-06T07:27:12.900Z │ 28.856              │ 139.556              │\n",
       "│ 10  │ 2000-10-04T16:58:44.310Z │ -15.421             │ 166.91               │\n",
       "⋮\n",
       "│ 253 │ 2016-11-13T11:02:56.340Z │ -42.7373            │ 173.054              │\n",
       "│ 254 │ 2016-12-08T17:38:46.280Z │ -10.6812            │ 161.327              │\n",
       "│ 255 │ 2016-12-17T10:51:10.500Z │ -4.5049             │ 153.522              │\n",
       "│ 256 │ 2016-12-25T14:22:27.010Z │ -43.4064            │ -73.9413             │\n",
       "│ 257 │ 2017-01-10T06:13:48.140Z │ 4.4782              │ 122.617              │\n",
       "│ 258 │ 2017-01-22T04:30:22.960Z │ -6.2464             │ 155.172              │\n",
       "│ 259 │ 2017-07-17T23:34:13.740Z │ 54.4434             │ 168.857              │\n",
       "│ 260 │ 2017-09-08T04:49:19.180Z │ 15.0222             │ -93.8993             │\n",
       "│ 261 │ 2017-09-19T18:14:38.090Z │ 18.5499             │ -98.4887             │\n",
       "│ 262 │ 2017-11-12T18:18:17.180Z │ 34.9109             │ 45.9592              │\n",
       "│ 263 │ 2017-11-19T22:43:29.250Z │ -21.3246            │ 168.672              │"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earthquakes_cities_historical_weather_df = create_earthquakes_cities_historical_weather_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"../earthquakes_csv/earthquakes_cities_historical_weather_df.csv\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CSV.write(\"../earthquakes_csv/earthquakes_cities_historical_weather_df.csv\", earthquakes_cities_historical_weather_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see for how many earthquakes with a magnitude 7-9, is the historical data available.\n",
    "\n",
    "The results are not very promissing, because that means that for the chosen magnitudes about 40 percent have weather data available.  The weather data for some of those the data will probably not be good because of how far the measurements (temp) from the earthquake epicenter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accumulator{Any,Int64} with 2 entries:\n",
       "  \"yes\" => 108\n",
       "  \"no\"  => 155"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter(earthquakes_cities_historical_weather_df.historical_temp_available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload the newly created dataframe \n",
    "(Just in case, I had to do this because I did an inplace modification of the orinal df and was left with an empty df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#earthquakes_cities_historical_weather_df = DataFrame(CSV.File(\"../earthquakes_csv/earthquakes_cities_historical_weather_df.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's start workig with the magnitude 7 or greater for which there is historical temperature data and it is from a distance of less than 300 kilometers**\n",
    "\n",
    "Create the new dataframe, we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>earthquake_time</th><th>earthquake_latitude</th><th>earthquake_longitude</th><th>earthquake_depth</th></tr><tr><th></th><th>String</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>67 rows × 9 columns (omitted printing of 5 columns)</p><tr><th>1</th><td>2001-01-10T16:02:44.230Z</td><td>57.078</td><td>-153.211</td><td>33.0</td></tr><tr><th>2</th><td>2001-01-26T03:16:40.500Z</td><td>23.419</td><td>70.232</td><td>16.0</td></tr><tr><th>3</th><td>2001-10-12T15:02:16.840Z</td><td>12.686</td><td>144.98</td><td>37.0</td></tr><tr><th>4</th><td>2002-04-26T16:06:07.000Z</td><td>13.088</td><td>144.619</td><td>85.7</td></tr><tr><th>5</th><td>2002-11-03T22:12:41.518Z</td><td>63.5141</td><td>-147.453</td><td>4.2</td></tr><tr><th>6</th><td>2003-05-26T09:24:33.400Z</td><td>38.849</td><td>141.568</td><td>68.0</td></tr><tr><th>7</th><td>2003-09-25T19:50:06.360Z</td><td>41.815</td><td>143.91</td><td>27.0</td></tr><tr><th>8</th><td>2003-09-25T21:08:00.030Z</td><td>41.774</td><td>143.593</td><td>33.0</td></tr><tr><th>9</th><td>2003-09-27T11:33:25.080Z</td><td>50.038</td><td>87.813</td><td>16.0</td></tr><tr><th>10</th><td>2003-10-31T01:06:28.280Z</td><td>37.812</td><td>142.619</td><td>10.0</td></tr><tr><th>11</th><td>2005-06-13T22:44:33.900Z</td><td>-19.987</td><td>-69.197</td><td>115.6</td></tr><tr><th>12</th><td>2005-06-15T02:50:54.190Z</td><td>41.292</td><td>-125.953</td><td>16.0</td></tr><tr><th>13</th><td>2005-08-16T02:46:28.400Z</td><td>38.276</td><td>142.039</td><td>36.0</td></tr><tr><th>14</th><td>2006-07-17T08:19:26.680Z</td><td>-9.284</td><td>107.419</td><td>20.0</td></tr><tr><th>15</th><td>2006-12-26T12:26:21.140Z</td><td>21.799</td><td>120.547</td><td>10.0</td></tr><tr><th>16</th><td>2007-08-08T17:05:04.920Z</td><td>-5.859</td><td>107.419</td><td>280.0</td></tr><tr><th>17</th><td>2007-08-15T23:40:57.890Z</td><td>-13.386</td><td>-76.603</td><td>39.0</td></tr><tr><th>18</th><td>2007-09-13T03:35:28.720Z</td><td>-2.13</td><td>99.627</td><td>22.0</td></tr><tr><th>19</th><td>2007-11-29T19:00:20.420Z</td><td>14.944</td><td>-61.274</td><td>156.0</td></tr><tr><th>20</th><td>2008-02-20T08:08:30.520Z</td><td>2.768</td><td>95.964</td><td>26.0</td></tr><tr><th>21</th><td>2008-05-12T06:28:01.570Z</td><td>31.002</td><td>103.322</td><td>19.0</td></tr><tr><th>22</th><td>2008-07-19T02:39:28.700Z</td><td>37.552</td><td>142.214</td><td>22.0</td></tr><tr><th>23</th><td>2009-02-11T17:34:50.490Z</td><td>3.886</td><td>126.387</td><td>20.0</td></tr><tr><th>24</th><td>2009-03-19T18:17:40.470Z</td><td>-23.043</td><td>-174.66</td><td>31.0</td></tr><tr><th>25</th><td>2009-08-09T10:55:55.110Z</td><td>33.167</td><td>137.944</td><td>292.0</td></tr><tr><th>26</th><td>2009-09-29T17:48:10.990Z</td><td>-15.489</td><td>-172.095</td><td>18.0</td></tr><tr><th>27</th><td>2009-09-30T10:16:09.250Z</td><td>-0.72</td><td>99.867</td><td>81.0</td></tr><tr><th>28</th><td>2009-11-09T10:44:55.110Z</td><td>-17.239</td><td>178.331</td><td>595.0</td></tr><tr><th>29</th><td>2010-01-12T21:53:10.060Z</td><td>18.443</td><td>-72.571</td><td>13.0</td></tr><tr><th>30</th><td>2010-02-26T20:31:26.970Z</td><td>25.93</td><td>128.425</td><td>25.0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccc}\n",
       "\t& earthquake\\_time & earthquake\\_latitude & earthquake\\_longitude & earthquake\\_depth & \\\\\n",
       "\t\\hline\n",
       "\t& String & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 2001-01-10T16:02:44.230Z & 57.078 & -153.211 & 33.0 & $\\dots$ \\\\\n",
       "\t2 & 2001-01-26T03:16:40.500Z & 23.419 & 70.232 & 16.0 & $\\dots$ \\\\\n",
       "\t3 & 2001-10-12T15:02:16.840Z & 12.686 & 144.98 & 37.0 & $\\dots$ \\\\\n",
       "\t4 & 2002-04-26T16:06:07.000Z & 13.088 & 144.619 & 85.7 & $\\dots$ \\\\\n",
       "\t5 & 2002-11-03T22:12:41.518Z & 63.5141 & -147.453 & 4.2 & $\\dots$ \\\\\n",
       "\t6 & 2003-05-26T09:24:33.400Z & 38.849 & 141.568 & 68.0 & $\\dots$ \\\\\n",
       "\t7 & 2003-09-25T19:50:06.360Z & 41.815 & 143.91 & 27.0 & $\\dots$ \\\\\n",
       "\t8 & 2003-09-25T21:08:00.030Z & 41.774 & 143.593 & 33.0 & $\\dots$ \\\\\n",
       "\t9 & 2003-09-27T11:33:25.080Z & 50.038 & 87.813 & 16.0 & $\\dots$ \\\\\n",
       "\t10 & 2003-10-31T01:06:28.280Z & 37.812 & 142.619 & 10.0 & $\\dots$ \\\\\n",
       "\t11 & 2005-06-13T22:44:33.900Z & -19.987 & -69.197 & 115.6 & $\\dots$ \\\\\n",
       "\t12 & 2005-06-15T02:50:54.190Z & 41.292 & -125.953 & 16.0 & $\\dots$ \\\\\n",
       "\t13 & 2005-08-16T02:46:28.400Z & 38.276 & 142.039 & 36.0 & $\\dots$ \\\\\n",
       "\t14 & 2006-07-17T08:19:26.680Z & -9.284 & 107.419 & 20.0 & $\\dots$ \\\\\n",
       "\t15 & 2006-12-26T12:26:21.140Z & 21.799 & 120.547 & 10.0 & $\\dots$ \\\\\n",
       "\t16 & 2007-08-08T17:05:04.920Z & -5.859 & 107.419 & 280.0 & $\\dots$ \\\\\n",
       "\t17 & 2007-08-15T23:40:57.890Z & -13.386 & -76.603 & 39.0 & $\\dots$ \\\\\n",
       "\t18 & 2007-09-13T03:35:28.720Z & -2.13 & 99.627 & 22.0 & $\\dots$ \\\\\n",
       "\t19 & 2007-11-29T19:00:20.420Z & 14.944 & -61.274 & 156.0 & $\\dots$ \\\\\n",
       "\t20 & 2008-02-20T08:08:30.520Z & 2.768 & 95.964 & 26.0 & $\\dots$ \\\\\n",
       "\t21 & 2008-05-12T06:28:01.570Z & 31.002 & 103.322 & 19.0 & $\\dots$ \\\\\n",
       "\t22 & 2008-07-19T02:39:28.700Z & 37.552 & 142.214 & 22.0 & $\\dots$ \\\\\n",
       "\t23 & 2009-02-11T17:34:50.490Z & 3.886 & 126.387 & 20.0 & $\\dots$ \\\\\n",
       "\t24 & 2009-03-19T18:17:40.470Z & -23.043 & -174.66 & 31.0 & $\\dots$ \\\\\n",
       "\t25 & 2009-08-09T10:55:55.110Z & 33.167 & 137.944 & 292.0 & $\\dots$ \\\\\n",
       "\t26 & 2009-09-29T17:48:10.990Z & -15.489 & -172.095 & 18.0 & $\\dots$ \\\\\n",
       "\t27 & 2009-09-30T10:16:09.250Z & -0.72 & 99.867 & 81.0 & $\\dots$ \\\\\n",
       "\t28 & 2009-11-09T10:44:55.110Z & -17.239 & 178.331 & 595.0 & $\\dots$ \\\\\n",
       "\t29 & 2010-01-12T21:53:10.060Z & 18.443 & -72.571 & 13.0 & $\\dots$ \\\\\n",
       "\t30 & 2010-02-26T20:31:26.970Z & 25.93 & 128.425 & 25.0 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "67×9 DataFrame. Omitted printing of 6 columns\n",
       "│ Row │ earthquake_time          │ earthquake_latitude │ earthquake_longitude │\n",
       "│     │ \u001b[90mString\u001b[39m                   │ \u001b[90mFloat64\u001b[39m             │ \u001b[90mFloat64\u001b[39m              │\n",
       "├─────┼──────────────────────────┼─────────────────────┼──────────────────────┤\n",
       "│ 1   │ 2001-01-10T16:02:44.230Z │ 57.078              │ -153.211             │\n",
       "│ 2   │ 2001-01-26T03:16:40.500Z │ 23.419              │ 70.232               │\n",
       "│ 3   │ 2001-10-12T15:02:16.840Z │ 12.686              │ 144.98               │\n",
       "│ 4   │ 2002-04-26T16:06:07.000Z │ 13.088              │ 144.619              │\n",
       "│ 5   │ 2002-11-03T22:12:41.518Z │ 63.5141             │ -147.453             │\n",
       "│ 6   │ 2003-05-26T09:24:33.400Z │ 38.849              │ 141.568              │\n",
       "│ 7   │ 2003-09-25T19:50:06.360Z │ 41.815              │ 143.91               │\n",
       "│ 8   │ 2003-09-25T21:08:00.030Z │ 41.774              │ 143.593              │\n",
       "│ 9   │ 2003-09-27T11:33:25.080Z │ 50.038              │ 87.813               │\n",
       "│ 10  │ 2003-10-31T01:06:28.280Z │ 37.812              │ 142.619              │\n",
       "⋮\n",
       "│ 57  │ 2014-11-15T02:31:41.720Z │ 1.8929              │ 126.522              │\n",
       "│ 58  │ 2015-03-29T23:48:31.010Z │ -4.7294             │ 152.562              │\n",
       "│ 59  │ 2015-07-27T21:41:21.710Z │ -2.6286             │ 138.528              │\n",
       "│ 60  │ 2015-10-20T21:52:02.560Z │ -14.8595            │ 167.303              │\n",
       "│ 61  │ 2015-11-24T22:45:38.880Z │ -10.5372            │ -70.9437             │\n",
       "│ 62  │ 2015-11-24T22:50:54.370Z │ -10.0598            │ -71.0184             │\n",
       "│ 63  │ 2016-01-24T10:30:30.230Z │ 59.6363             │ -153.405             │\n",
       "│ 64  │ 2016-01-30T03:25:12.220Z │ 53.9776             │ 158.546              │\n",
       "│ 65  │ 2016-04-15T16:25:06.220Z │ 32.7906             │ 130.754              │\n",
       "│ 66  │ 2016-11-13T11:02:56.340Z │ -42.7373            │ 173.054              │\n",
       "│ 67  │ 2017-09-19T18:14:38.090Z │ 18.5499             │ -98.4887             │"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_temperature_df = filter(row -> (row.historical_temp_available == \"yes\" && row.nearest_city_distance <= 300), earthquakes_cities_historical_weather_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generate_historical_dates (generic function with 1 method)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to generate the dates ~90 days, for that year and the previous years.\n",
    "function generate_historical_dates(timestamp)\n",
    "    date = DateTime(strip(timestamp, last(timestamp))) # remove the \"Z\"\n",
    "    date_array = []\n",
    "    for i in 0:4\n",
    "        for j in 0:90\n",
    "            push!(date_array, (date - Day(j) - Year(i)))\n",
    "        end\n",
    "    end\n",
    "    return date_array\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to test a couple of times for 5 years, 90 days of data for each.\n",
    "# save all the historical data.  This will mark the Air temperature data complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets look at the temperature data from the API response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{\\\"latitude\\\":25.93,\\\"longitude\\\":128.425,\\\"timezone\\\":\\\"Asia/Tokyo\\\",\\\"currently\\\":{\\\"time\\\":1267129887,\\\"uvIndex\\\":0},\\\"flags\\\":{\\\"sources\\\":[\\\"cmc\\\",\\\"gfs\\\",\\\"icon\\\",\\\"isd\\\",\\\"madis\\\"],\\\"nearest-station\\\":47.944,\\\"units\\\":\\\"us\\\"},\\\"offset\\\":9}\\n\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: both DataFrames and HTTP export \"stack\"; uses of it in module Main must be qualified\n"
     ]
    }
   ],
   "source": [
    "c = get_historical_weather(25.93, 128.425, 1267129887)\n",
    "#temperature_info = get_historical_weather(25.93, 128.425,\"2010-02-26T20:31:26.970Z\")\n",
    "#temperature_info = get_historical_weather(4.102, 123.907, \"2001-10-19T03:28:44.460Z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String,Any} with 7 entries:\n",
       "  \"latitude\"  => 25.93\n",
       "  \"hourly\"    => Dict{String,Any}(\"data\"=>Any[Dict{String,Any}(\"visibility\"=>6.…\n",
       "  \"flags\"     => Dict{String,Any}(\"units\"=>\"us\",\"sources\"=>Any[\"cmc\", \"gfs\", \"i…\n",
       "  \"longitude\" => 128.425\n",
       "  \"offset\"    => 9\n",
       "  \"timezone\"  => \"Asia/Tokyo\"\n",
       "  \"currently\" => Dict{String,Any}(\"time\"=>1267216287,\"uvIndex\"=>0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_info_json = JSON.parse(temperature_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Any,1}:\n",
       " Dict{String,Any}(\"visibility\" => 6.216,\"apparentTemperature\" => 73.48,\"time\" => 1267207200,\"pressure\" => 1013,\"windSpeed\" => 14.96,\"humidity\" => 0.86,\"dewPoint\" => 68,\"uvIndex\" => 0,\"temperature\" => 72.49,\"windBearing\" => 240…)\n",
       " Dict{String,Any}(\"visibility\" => 6.216,\"apparentTemperature\" => 73.48,\"time\" => 1267210800,\"pressure\" => 1013,\"windSpeed\" => 14.96,\"humidity\" => 0.86,\"dewPoint\" => 68,\"uvIndex\" => 0,\"temperature\" => 72.49,\"windBearing\" => 240…)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_info_json[\"hourly\"][\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String,Any} with 10 entries:\n",
       "  \"visibility\"          => 6.216\n",
       "  \"apparentTemperature\" => 73.48\n",
       "  \"time\"                => 1267207200\n",
       "  \"pressure\"            => 1013\n",
       "  \"windSpeed\"           => 14.96\n",
       "  \"humidity\"            => 0.86\n",
       "  \"dewPoint\"            => 68\n",
       "  \"uvIndex\"             => 0\n",
       "  \"temperature\"         => 72.49\n",
       "  \"windBearing\"         => 240"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_info_json[\"hourly\"][\"data\"][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String,Any} with 10 entries:\n",
       "  \"visibility\"          => 6.216\n",
       "  \"apparentTemperature\" => 73.48\n",
       "  \"time\"                => 1267210800\n",
       "  \"pressure\"            => 1013\n",
       "  \"windSpeed\"           => 14.96\n",
       "  \"humidity\"            => 0.86\n",
       "  \"dewPoint\"            => 68\n",
       "  \"uvIndex\"             => 0\n",
       "  \"temperature\"         => 72.49\n",
       "  \"windBearing\"         => 240"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_info_json[\"hourly\"][\"data\"][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.49"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_info_json[\"hourly\"][\"data\"][:2][\"temperature\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets create historical temperature dataset per earthquake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "Base.IOError",
     "evalue": "IOError: mkdir: file already exists (EEXIST)",
     "output_type": "error",
     "traceback": [
      "IOError: mkdir: file already exists (EEXIST)",
      "",
      "Stacktrace:",
      " [1] uv_error at ./libuv.jl:97 [inlined]",
      " [2] mkdir(::String; mode::UInt16) at ./file.jl:177",
      " [3] mkdir(::String) at ./file.jl:170",
      " [4] top-level scope at In[39]:1"
     ]
    }
   ],
   "source": [
    "# Create a directory to store the data, if the directory exist it won't overwrite it.\n",
    "mkdir(\"../temperature_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_temperature_data (generic function with 1 method)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function create_temperature_data(latitude, longitude, timestamp)\n",
    "    \n",
    "    temperature_df = DataFrame(unix_time = Int64[], temperature = Float64[], temperature_json = Any)\n",
    "    unixtime_array = generate_historical_unixtime(timestamp)\n",
    "    \n",
    "    for unixtime in unixtime_array\n",
    "        println(unixtime, typeof(unixtime))\n",
    "        temperature_data = get_historical_weather(latitude, longitude, unixtime)\n",
    "        println(temperature_data)\n",
    "        temperature_data_json = JSON.parse(temperature_data)\n",
    "        \n",
    "        push!(temperature_df, (unix_time = unixtime,\n",
    "                               temperature = temperature_data_json[\"hourly\"][\"data\"][:1][\"temperature\"],\n",
    "                               temperature_json = temperature_data_json))\n",
    "    end\n",
    "    \n",
    "    return temperature_df\n",
    "    \n",
    "end\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the function to create the temperature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArgumentError",
     "evalue": "ArgumentError: Invalid DateTime string",
     "output_type": "error",
     "traceback": [
      "ArgumentError: Invalid DateTime string",
      "",
      "Stacktrace:",
      " [1] parse(::Type{DateTime}, ::String, ::DateFormat{Symbol(\"yyyy-mm-dd\\\\THH:MM:SS.s\"),Tuple{Dates.DatePart{'y'},Dates.Delim{Char,1},Dates.DatePart{'m'},Dates.Delim{Char,1},Dates.DatePart{'d'},Dates.Delim{Char,1},Dates.DatePart{'H'},Dates.Delim{Char,1},Dates.DatePart{'M'},Dates.Delim{Char,1},Dates.DatePart{'S'},Dates.Delim{Char,1},Dates.DatePart{'s'}}}) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.4/Dates/src/parse.jl:277",
      " [2] DateTime at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.4/Dates/src/io.jl:482 [inlined] (repeats 2 times)",
      " [3] unix_time(::String) at ./In[67]:9",
      " [4] generate_historical_unixtime(::String) at ./In[47]:6",
      " [5] create_temperature_data(::Float64, ::Float64, ::String) at ./In[45]:4",
      " [6] top-level scope at In[68]:1"
     ]
    }
   ],
   "source": [
    "test_df = create_temperature_data(25.93, 128.45, \"2010-02-26T20:31:26.970Z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#= Once this is tested and works\n",
    "create function to create all temperatures datasets,\n",
    "create function to save all datasets to the temperature_data directory\n",
    "Fix the \n",
    "=# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "450-element Array{Any,1}:\n",
       " 2010-02-25T20:31:26.97\n",
       " 2010-02-24T20:31:26.97\n",
       " 2010-02-23T20:31:26.97\n",
       " 2010-02-22T20:31:26.97\n",
       " 2010-02-21T20:31:26.97\n",
       " 2010-02-20T20:31:26.97\n",
       " 2010-02-19T20:31:26.97\n",
       " 2010-02-18T20:31:26.97\n",
       " 2010-02-17T20:31:26.97\n",
       " 2010-02-16T20:31:26.97\n",
       " 2010-02-15T20:31:26.97\n",
       " 2010-02-14T20:31:26.97\n",
       " 2010-02-13T20:31:26.97\n",
       " ⋮\n",
       " 2005-12-09T20:31:26.97\n",
       " 2005-12-08T20:31:26.97\n",
       " 2005-12-07T20:31:26.97\n",
       " 2005-12-06T20:31:26.97\n",
       " 2005-12-05T20:31:26.97\n",
       " 2005-12-04T20:31:26.97\n",
       " 2005-12-03T20:31:26.97\n",
       " 2005-12-02T20:31:26.97\n",
       " 2005-12-01T20:31:26.97\n",
       " 2005-11-30T20:31:26.97\n",
       " 2005-11-29T20:31:26.97\n",
       " 2005-11-28T20:31:26.97"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_historical_dates(\"2010-02-26T20:31:26.970Z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
